# AUTOGENERATED! DO NOT EDIT! File to edit: 10_evalitr.ipynb (unless otherwise specified).

__all__ = ['main', 'merge']

# Cell
from .lunarlander import register as lunarlander_register
from .bipedalwalker import register as biepdalwalker_register
from .carracing import register as carracing_register
lunarlander_register()
biepdalwalker_register()
carracing_register()

# Cell
from sandbox.rocky.tf.envs.base import TfEnv
from rllab.envs.gym_env import GymEnv
from .itirl import ITIRL
from .model import ITIRL_Net
from .policy import NoisyControlPolicy
import tensorflow as tf
from rllab.misc import logger
from airl.utils.log_utils import rllab_logdir, load_latest_experts
from rllab.envs.noisy_env import NoisyActionEnv
import numpy as np
import fire
import os
import pickle
import pandas as pd

def main(name, method_name, type_status, eval_batch_size, max_path_length, itr, n_parallel, num_steps=100, num_trials=10, is_training=True, with_true_weights=False, noise=0, n_itrs=200, sigma_scale=1.0, discount=1.0, p_lambda=0.1, p_alpha=1.0):
    tf.reset_default_graph()
    env = TfEnv(NoisyActionEnv(GymEnv(name, record_video=False, record_log=False), act_noise=noise))
    env.type_status = type_status

    mean = np.zeros(env.spec.action_space.flat_dim)
    sigma = np.eye(env.spec.action_space.flat_dim)*sigma_scale

    if type_status == "CarRacing":
        irl_model = ITIRL_Net(env.spec, alpha=p_alpha, p_lambda=p_lambda, sigma=sigma, l2_reg=8e-5, network_type="CONV", batch_size=eval_batch_size)
    else:
        irl_model = ITIRL_Net(env.spec, alpha=p_alpha, p_lambda=p_lambda, sigma=sigma, l2_reg=8e-5)
    # irl_model = ITIRL_Net(env.spec, expert_trajs=None, alpha=p_alpha, p_lambda=p_lambda, sigma=sigma, l2_reg=1e-4)
    policy = NoisyControlPolicy(env.spec, mean, sigma, p_alpha, p_lambda)
    method = ITIRL(env, policy, irl_model=irl_model, batch_size=eval_batch_size, max_path_length=max_path_length, n_itr=n_itrs, discount=discount)

    with rllab_logdir(algo=method, dirname=f"data/{method_name}"):
        # Assume that you have 12GB of GPU memory and want to allocate ~4GB:
        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7/(n_parallel))
        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:
            method.start_worker(n_parallel*5)
            method.itr_eval(sess, itr, is_training=is_training, with_true_weights=with_true_weights, num_steps=num_steps, num_trials=num_trials)

def merge(method_name, n_itrs, is_training, with_true_weights, skip=1):
    with rllab_logdir(algo=None, dirname=f"data/{method_name}"):
        info = []
        for itr in range(0, n_itrs, skip):
            fn = os.path.join(logger.get_snapshot_dir(), f'eval_{itr}_train_{is_training}_groundtruth_{with_true_weights}.pkl')
            with open(fn, 'rb') as f:
                res = pickle.load(f)
            print (res)
            info.append([itr,] + list(res))
        info=np.array(info)
        C = ['Iteration', 'AverageReturn', 'AverageDiscountedReturn']
        df = pd.DataFrame(info) # A is a numpy 2d array
        fn = os.path.join(logger.get_snapshot_dir(), f'train_{is_training}_groundtruth_{with_true_weights}_progress.csv')
        df.to_csv(fn, header=C,index=False)

fire.Fire({
    "main" : main,
    "merge": merge
})