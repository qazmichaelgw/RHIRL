# AUTOGENERATED! DO NOT EDIT! File to edit: 00_main.ipynb (unless otherwise specified).

__all__ = ['main']

# Cell
from .lunarlander import register as lunarlander_register
from .bipedalwalker import register as biepdalwalker_register
from .carracing import register as carracing_register
lunarlander_register()
biepdalwalker_register()
carracing_register()

# Cell
from sandbox.rocky.tf.envs.base import TfEnv
from rllab.envs.gym_env import GymEnv
from .itirl import ITIRL
from .model import ITIRL_Net
from .policy import NoisyControlPolicy
import tensorflow as tf
from rllab.misc import logger
from airl.utils.log_utils import rllab_logdir
from sandbox.rocky.tf.samplers.batch_sampler import BatchSampler
from sandbox.rocky.tf.samplers.vectorized_sampler import VectorizedSampler
from rllab.envs.noisy_env import NoisyActionEnv
import numpy as np
import fire
import sys

def main(name, expert_datadir, method_name, type_status, batch_size, max_path_length, noise=0, sigma_scale=1.0, num_demos=5, n_itrs=200, discount=1.0, p_alpha=1.0, p_lambda=0.1):
    valid_types = ['classic', 'Box2D', 'mujoco', "CarRacing"]
    # because the experts store in different format....
    # here add some adjustment.
    if noise == 0:
        num_demos = 6
    else:
        num_demos = 12
    # num_demos=1
    tf.reset_default_graph()
    #name='LunarLanderContinuous-v2'
    #name='LunarLanderStateful-v0'
    #name='Pendulum-v0'
    # env = TfEnv(GymEnv('BipedalWalker-v2', record_video=False, record_log=False))
    env = TfEnv(NoisyActionEnv(GymEnv(name, record_video=False, record_log=False), act_noise=noise))
    # noisy environment with less path length
    # max_path_length = max(int(max_path_length/(5*noise + 1)), 30)
    # must set env type_status if it is not a classic control
    #env.type_status="classic"
    env.type_status=type_status
    assert env.type_status in valid_types

    mean = np.zeros(env.spec.action_space.flat_dim)
    sigma = np.eye(env.spec.action_space.flat_dim)*sigma_scale

    if type_status == "CarRacing":
        irl_model = ITIRL_Net(env.spec, alpha=p_alpha, p_lambda=p_lambda, sigma=sigma, l2_reg=8e-5, network_type="CONV", batch_size=batch_size)
    else:
        irl_model = ITIRL_Net(env.spec, alpha=p_alpha, p_lambda=p_lambda, sigma=sigma, l2_reg=8e-5)
    policy = NoisyControlPolicy(env.spec, mean, sigma, p_alpha, p_lambda)
    method = ITIRL(env, policy, irl_model=irl_model, batch_size=batch_size, max_path_length=max_path_length, n_itr=n_itrs, expert_datadir=expert_datadir, num_demos=num_demos, discount=discount)

    with rllab_logdir(algo=method, dirname=f'data/{method_name}'):
        with tf.Session() as sess:
            method.train(sess)

fire.Fire(main)