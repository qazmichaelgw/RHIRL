# AUTOGENERATED! DO NOT EDIT! File to edit: 01_Policy.ipynb (unless otherwise specified).

__all__ = ['NoisyControlPolicy']

# Cell
from sandbox.rocky.tf.policies.base import Policy
from rllab.core.serializable import Serializable
from rllab.misc.overrides import overrides
import rllab.misc.logger as logger
import numpy as np
import tensorflow as tf
from scipy.signal import savgol_filter

# Cell
class NoisyControlPolicy(Policy, Serializable):
    """noisy policy on the nominal control"""
    def __init__(self, env_spec, mean, sigma, alpha, p_lambda):
        Serializable.quick_init(self, locals())
        super(NoisyControlPolicy, self).__init__(env_spec)
        self.mean = mean
        self.sigma = sigma
        self.inverse_sigma = np.linalg.inv(sigma)
        self.alpha = alpha
        self.gamma = p_lambda*(1-alpha)
        self.max_path_length = None
        self.max_trajs = None
        # helper function for control update
        self.cur_step = None
        self.cur_traj = None
        self.nominal_control=None

    def init_info(self, max_trajs, max_path_length, u_dim, n_itrs):
        self.max_path_length = max_path_length
        self.max_trajs = max_trajs
        # nominal contorl of current state
        # nominal control should be the max depth length
        # initial nominal control is uncontroled dynamics
        # maintain a history of best policies
        self.nominal_control = np.zeros((max_path_length, u_dim))
        # for carracing, given a initial speed
#         self.nominal_control[:, 1] = 0.7
        self.org_control = self.nominal_control
        self.hist_control = np.zeros((n_itrs+max_path_length, u_dim))
        # self.hist_control[:,1] = 1

    def update_idx(self, cur_step, cur_traj):
        self.cur_step = cur_step
        self.cur_traj = cur_traj

    def update_nominal_control(self, control):
        # control = np.clip(control, self.action_space.low, self.action_space.high)
        self.nominal_control = control
        # print ("nominal control", control)

    def elapse_one_step(self, step=None):
        if step is not None:
            self.hist_control[step:step+self.max_path_length, :] = self.nominal_control
        self.nominal_control = np.roll(self.nominal_control, -1, axis=0)
        self.nominal_control[-1,:] = 0
        # reset nomial control for car racing only
#         self.nominal_control[:, 1] = 0.5
#         self.nominal_control = self.org_control

    @property
    def vectorized(self):
        return True

    def get_params_internal(self, **tags):
        return []

    def get_current_control(self):
        return np.clip(self.nominal_control[0], self.action_space.low, self.action_space.high)

    @overrides
    def get_action(self, observation):
        actions, agent_infos = self.get_actions([observation])
        return actions[0], {k: v[0] for k, v in agent_infos.items()}

    @overrides
    def get_actions(self, observations):
        xi = np.random.multivariate_normal(self.mean, self.sigma, len(observations))
        if self.cur_traj < self.alpha*self.max_trajs:
            vt = xi + self.nominal_control[self.cur_step]
        else:
            vt = xi
        control_cost = self.gamma * np.matmul(np.matmul(self.nominal_control[self.cur_step], self.inverse_sigma), vt.T)
        # clip to the valid interval
        actions = np.clip(vt, self.action_space.low, self.action_space.high)

        # debug
#         actions[:,:] = np.ones(actions[0,:].shape)
        #print ('action shape', actions.shape, control_cost.shape, xi.shape)
        return actions, dict(control_cost=control_cost, xi=xi)

    def log_diagnostics(self, paths):
        logger.record_tabular('NominalControl mean', np.mean(self.nominal_control))
        logger.record_tabular('NominalControl std', np.std(self.nominal_control))
